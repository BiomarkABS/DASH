---
title: "Import and QC of OTG Data"
author: Mike Ackerman
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{otg-import-qc}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE, message = FALSE, warning = FALSE, results = "hide"}
# knitr options
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = TRUE,
  comment = "#>"
)

```

# Introduction

Welcome to the [DASH](https://github.com/BiomarkABS/DASH) R package! This vignette, which logically follows as the first of multiple vignettes in the package, describes how to import and quality control (QC) on-the-ground (OTG hereafter) collected habitat data  using the DASH protocol. The initial data collection forms to record the OTG data were generated using [ArcGIS Survey123](https://www.esri.com/en-us/arcgis/products/arcgis-survey123/overview) and we focus on importing data from those forms. After data import, we describe how functions included in the DASH R package can then be used to perform QC on the data to identify potential errors, perhaps that occurred in the field. Finally, we describe initial data cleaning and joining (i.e., joining channel unit scale information with wood, undercut, etc. information collected for that unit) in preparation of attaching the OTG collected data to stream centerline data to make it spatial. Later, our spatial OTG data can then be connected to drone-generation orthomosaics. 

Let's start by describing the data import procedure; we'll then go into data QC and how to resolve some of the identified errors. Begin by loading the necessary libraries (R packages) needed for this vignette and analysis:

```{r setup}
# load necessary libraries
library(DASH)
library(tibble)
library(janitor)
library(dplyr)
library(magrittr)

```

# Data Import

Start data import text here...

```{r otg-path}
# to your desktop
otg_path = "C:/Users/username/Desktop/1_formatted_csvs/"

# e.g., Biomark NAS
# set NAS prefix, depending on your operating system
if(.Platform$OS.type != 'unix') {
  nas_prefix = "S:"
} else if(.Platform$OS.type == 'unix') {
  nas_prefix = "~/../../Volumes/ABS"
}

# path to otg data
otg_path = paste0(nas_prefix, "/data/habitat/DASH/OTG/2019/lemhi/1_formatted_csvs/")

```

```{r read-otg-csv, eval = F}
# read in just one type of OTG data at a time
otg_raw_cu = read_otg_csv(path = otg_path,
                          otg_type = "CU_1.csv")

otg_raw_wood = read_otg_csv(path = otg_path,
                            otg_type = "Wood_2.csv")

```

```{r read-otg-csv-wrapper, eval = F}
# "loop over" all data types using read_otg_csv_wrapper()
otg_raw = read_otg_csv_wrapper(path = otg_path,
                               otg_type_list = c("surveyPoint_0.csv",
                                                   "CU_1.csv",
                                                   "Wood_2.csv",
                                                   "Jam_3.csv",
                                                   "Undercut_4.csv",
                                                   "Discharge_5.csv",
                                                   "DischargeMeasurements_6.csv"),
                                 otg_type_names = c("survey",
                                                    "cu",
                                                    "wood",
                                                    "jam",
                                                    "undercut",
                                                    "discharge",
                                                    "discharge_measurements"))

```

```{r view-raw-otg}
head(otg_raw$cu)

```

```{r save-raw-otg, eval = F}
save(otg_raw,
     file = paste0(nas_prefix, "/data/habitat/DASH/OTG/2019/lemhi/prepped/otg_raw.rda"))

```

# Initial QC

```{r fake-load-raw-otg, eval = F}
load(paste0(nas_prefix,
            "/data/habitat/DASH/OTG/2019/lemhi/prepped/otg_raw.rda"))

```

```{r init-qc, eval = F}
# QC one data type at a time
init_qc_cu = qc_cu(qc_df = otg_raw$cu)

init_qc_wood = qc_wood(qc_df = otg_raw$wood)

# join qc results together
init_qc_some = init_qc_cu %>%
  add_column(source = "CU",
             .before = 0) %>%
  bind_rows(init_qc_wood %>%
              add_column(source = "Wood",
                         .before = 0))

```

```{r init-qc-all}
# same as above
init_qc_some = qc_wrapper(cu_df = otg_raw$cu,
                          wood_df = otg_raw$wood,
                          redirect_output = FALSE)

# QC all OTG data types at once
init_qc = qc_wrapper(survey_df = otg_raw$survey,
                     cu_df = otg_raw$cu,
                     wood_df = otg_raw$wood,
                     jam_df = otg_raw$jam,
                     undercut_df = otg_raw$undercut,
                     discharge_df = otg_raw$discharge,
                     disch_meas_df = otg_raw$discharge_measurements,
                     redirect_output = FALSE)

```

# Examine QC Results

```{r examine-qc}
tabyl(init_qc,
      source)

init_qc %>%
  print()

```

```{r max-depth-errors}
init_qc %>%
  filter(source == "CU") %>%
  filter(grepl("Column Maximum Depth", error_message)) %>%
  left_join(otg_raw$cu) %>%
  select(source:error_message, `Channel Unit Type`, `Maximum Depth (m)`)
  
```

```{r ocular-ests-errors}
init_qc %>%
  filter(source == "CU") %>%
  filter(grepl("Ocular estimates", error_message)) %>%
  left_join(otg_raw$cu) %>%
  select(source:GlobalID,
         `Channel Unit Type`,
         `Sand/Fines 2mm`:`Boulder 256mm`) %>%
  mutate(sum_ocular = rowSums(.[5:8], na.rm = T))
  
```

```{r fish-cover-errors}
init_qc %>%
  filter(source == "CU") %>%
  filter(grepl("Cover values", error_message)) %>%
  left_join(otg_raw$cu) %>%
  select(source:GlobalID,
         `Overhanging Cover`:`Total No Cover`) %>%
  mutate(sum_cover = rowSums(.[4:8], na.rm = T))
  
```

```{r undercut-errors}
init_qc %>%
  filter(source == "Undercut") %>%
  left_join(otg_raw$undercut) %>%
  select(path_nm:error_message,
         `Undercut Number`:`Width 75% (m)`)
  
```

```{r save-qc, eval = F}
# write QC results to .csv
write_csv(init_qc,
          paste0(nas_prefix, "/data/habitat/DASH/OTG/2019/lemhi/1_formatted_csvs/init_qc.csv"))

```

# Resolving Errors

# "Final" QC

# Data Wrangling and Export

#### END IMPORT AND QC VIGNETTE

<!-- *Holy Guacamole! That deserves a beer!* -->
